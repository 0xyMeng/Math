---
sort: 3
---
# 大数定律

## 概率和统计的关系


后面的章节是讲统计的，前面的是讲概率的。概率和统计是两个事情，但是几乎都是同时出现的。

要搞清楚概率里的概念和统计里的概念，一个是客观实在上帝视角，一个是我做实验的结果，是和实际有差别的。在实验次数足够多，这两个数值上就接近了。


概率与统计的关系在大数定律里面可以体会的到。

概率是个很好理解的事情，所以前面没有一上来就说概率和统计的区别。

实际上统计也是一个为了应用概率理论产生的工程问题。

我们都知道全国人民的身高平均值，肯定有个客观的数。即EX是确定的。如果某个什么营养学会想看看全国人民的平均身高变化，该怎么找出这个客观的EX


依靠义务教育，朴素的感情告诉我，找个几百人量一下基本上也就能反映出大概情况了。

也就是说

$$ \frac{1}{n}\sum_{i=1}^nX_k \to \mu  $$

更严谨的表示，大数定律

## 大数定律

在记公式以前看看这个定理的名字。大数定律，说明是在数据量足够多以后才满足的。

大数定律只讲了一个事情：样本足够多，样本均值一定等于数学期望。

样本足够多就是取极限，一定的含义就是这是个概率，如果有意外那也是成立的。

- 辛钦大数定律

独立同分布，存在期望

$$ \lim_{n \to \infty} P \left\{ \left| \frac{1}{n}\sum_{i=1}^nX_k - \mu \right| < \varepsilon \right\} = 1  $$

- 伯努利大数定律

当辛钦大数定律里面的那个实验结果是二选一既发生或不发生，那么辛钦大数定律就单独拎出来，发生的次数基本上就是发生的概率

$$ \lim_{n \to \infty} P \left\{ \left| \frac{f_A}{n} - p \right| < \varepsilon \right\} = 1  $$

这就是很经典的“频率代替概率”的理论基础。


## 中心极限定理


$$ X_i $$独立同分布，$$ EX_i = \mu, DX_i=\sigma^2 $$

数量足够多全部加起来，服从$$ N(n\mu, n\sigma^2) $$，一般来说，更喜欢用标准正态分布的形式，可以直接查表。

$$ \lim_{n \to \infty } P \left \{ \frac{\sum^n_{i=1} X_i - n\mu }{\sqrt{n}\sigma} \le x \right\} = \Phi(x)$$









