---
sort: 2
---
# 矩阵变换
<!--矩阵与变换-->

## 矩阵与变换的关系

线性变换可以理解为函数的另一种说法，$$ \boldsymbol{y} = L(\boldsymbol{x}) $$，线性变换接收一个向量，输出一个向量。可以用运动理解变换，一个向量经过一个线性变换的拉伸与旋转成为另一个向量。

用数值描述线性变换的方法，只需记录基向量$$\boldsymbol{i}$$和$$\boldsymbol{j}$$变换后的位置。

例如向量$$ \boldsymbol\alpha = [-1,2]^T= -1\boldsymbol{i} + 2\boldsymbol{j} $$，变换后的基向量为$$\boldsymbol{\hat{i}}$$和$$\boldsymbol{\hat{j}}$$，变换后的$$\boldsymbol\alpha$$也是变换后基向量同样的线性组合。假设$$\color{red}\boldsymbol{\hat{i}} = [1,-2]^T$$，$$\color{blue}\boldsymbol{\hat{j}} = [3,0]^T$$，则组合方式不变，在原来的坐标系中表示变换后的向量：
$$ \boldsymbol{\hat{\alpha}} = -1\color{red}\boldsymbol{\hat{i}} \color{black} + 2\color{blue}\boldsymbol{\hat{j}} \color{black} = [\color{red}\boldsymbol{\hat{i}} \color{black},\color{blue}\boldsymbol{\hat{j}} \color{black}]\cdot\begin{bmatrix} -1 \\ 2 \end{bmatrix} = \begin{bmatrix} \color{red}-1 & \color{blue}3 \\ \color{red}-2 & \color{blue}0 \end{bmatrix} \begin{bmatrix} -1 \\ 2 \end{bmatrix} = \begin{bmatrix} 5 \\ 2 \end{bmatrix}$$

反过来

$$ \begin{bmatrix} \color{red}-1 & \color{blue}3 \\ \color{red}-2 & \color{blue}0 \end{bmatrix} \begin{bmatrix} -1 \\ 2 \end{bmatrix} = -1 \begin{bmatrix} \color{red}-1 \\ \color{red}-2 \end{bmatrix} + 2\begin{bmatrix} \color{blue}3 \\ \color{blue}0 \end{bmatrix} = -1\color{red}\boldsymbol{\hat{i}} \color{black} + 2\color{blue}\boldsymbol{\hat{j}} $$



即一个二维线性变换仅由4个数字即可完全确定，矩阵$$ \begin{bmatrix} \color{red}-1 & \color{blue}3 \\ \color{red}-2 & \color{blue}0 \end{bmatrix} $$的两个列可以理解为变换后的基向量。反过来如果想知道一个矩阵对一个向量的作用，只需要取出向量坐标与矩阵对应向量相乘后相加即可，这便是数乘和加法的思想，和在标准坐标系中缩放基向量在相加是一样的。

更一般的，用这个思想推导矩阵与向量的乘法：

$$ \begin{bmatrix} \color{red}a & \color{blue}b \\ \color{red}c & \color{blue}d \end{bmatrix} \begin{bmatrix} x \\ y \end{bmatrix} = x \begin{bmatrix} \color{red}a \\ \color{red}c \end{bmatrix} + 2\begin{bmatrix} \color{blue} b \\ \color{blue} d \end{bmatrix} = x \color{red}\boldsymbol{\hat{i}} \color{black} + y \color{blue}\boldsymbol{\hat{j}} \color{black} = \begin{bmatrix} \color{red} a \color{black} x + \color{blue} b \color{black} y \\ \color{red} c \color{black} x + \color{blue} d \color{black} y \\ \end{bmatrix}$$

按照前面坐标的思路，$$ \boldsymbol{A\cdot\alpha} = \boldsymbol{\beta} = \boldsymbol{E\cdot\beta}$$这个式子的含义，向量$$\boldsymbol{\beta}$$的坐标是对标准坐标系$$\boldsymbol{E}$$而言的，而向量$$\boldsymbol{\alpha}$$在前面乘了个矩阵的含义是这个坐标是在坐标系$$ \boldsymbol{A} $$中的坐标（$$ \boldsymbol{A} $$是矩阵，但是这里我把他叫成了坐标系，这个说法不是书上严格定义的，是按照我自己的理解来的，可能有不合适的地方。这里矩阵$$ \boldsymbol{A} = [\boldsymbol{x}, \boldsymbol{y}]$$，看作两个基向量，这么叫也是有依据的）

再从函数的角度来看$$ \boldsymbol{y} = L(\boldsymbol{x}) = L(x \color{red}\boldsymbol{i} \color{black} + y \color{blue}\boldsymbol{j}) \color{black} = xL(\color{red}\boldsymbol{i} \color{black} ) + yL(\color{blue}\boldsymbol{j}) \color{black} $$线性系统叠加性与均匀性。即一个向量的变换，等效于合成该向量的基向量的变换的合成。

一个特殊情况：如果变换后的$$\boldsymbol{\hat{i}\hat{j}}$$是线性相关的，例如矩阵$$ \begin{bmatrix} 2 & -2 \\ 1 & -1 \end{bmatrix} $$，这个线性变换将二维空间压缩到一条直线上，也就是$$\boldsymbol{\hat{i}\hat{j}}$$张成的一维空间，这个事情在后面会说。

## 矩阵乘法与连续变换

考虑连续两个变换作用在一个向量上，先用$$[■(0&-1@1&0)]$$做逆时针90°旋转，再用[■(1&1@0&1)]做剪切变换，先给出结果，这两个变换的复合变换为[■(1&-1@1&0)]。
用数学语言描述[■(1&1@0&1)]([■(0&-1@1&0)][■(x@y)])=[■(1&-1@1&0)][■(x@y)]，对一个向量进行旋转然后进行剪切变换，结果与直接对向量进行复合变换相同。因此[■(1&1@0&1)][■(0&-1@1&0)]=[■(1&1@0&1)]，定义为矩阵乘积是合理的，但是需要从右往左读，和函数符合f(g(x))类似。
用数值方法来得出这个结果：M_1=[i ̂,j ̂ ]中的代表了旋转变换后基向量的位置，在M_2作用下M_2 i ̂=[■(1&1@0&1)][■(0@1)]=0[■(0@1)]+1[■(1@1)]=[■(1@1)]，M_2 j ̂=[■(1&1@0&1)][■(-1@0)]=-1[■(1@0)]+0[■(1@1)]=[■(-1@0)]，这样得到了最终的两个基向量，放到同一个矩阵里有M_2 M_1=[■(1&1@0&1)][■(0&-1@1&0)]=[■(1&-1@1&0)]。
对一个普适性的矩阵：
M_2 M_1=[■(a&b@c&d)][■(e&f@g&h)]=[■(e[■(a@c)]+g[■(b@d)]&f[■(a@c)]+h[■(b@d)] )]=[■(ae+bg&af+bh@ce+dg&cf+dh)]
由此的问题：交换矩阵相乘顺序会对结果有影响吗？显然会的，先旋转后剪切和先剪切后旋转显然会看出基向量夹角不同。类似的矩阵乘法的结合律(AB)C=A(BC)，不论怎么结合都是先用C变换，再用B变换最后用A变换，变换顺序一样。

## 高维空间中的线性变换

同样的跟踪三个三维基向量i,j,k，即可代表三维空间中的线性变换。
和二维中类似，矩阵向量乘法：
[■(0&1&2@3&4&5@6&7&8)][■(x@y@z)]=x[■(0@3@6)]+y[■(1@4@7)]+z[■(2@5@8)]
矩阵乘法：
[■(0&-2&2@5&1&5@1&4&-1)][■(0&1&2@3&4&5@6&7&8)]=[■(6&6&6@33&44&55@6&10&14)]
第一列：0[■(0@5@1)]+3[■(-2@1@4)]+6[■(2@5@-1)]=[■(6@33@6)]
第二列：1[■(0@5@1)]+4[■(-2@1@4)]+7[■(2@5@-1)]=[■(6@44@10)]
第二列：2[■(0@5@1)]+5[■(-2@1@4)]+8[■(2@5@-1)]=[■(6@55@14)]

## 变换中的特殊情况：降维

用矩阵表示线性变换，想知道一个变换对空间多少拉伸或挤压，即测量变换后面积变化的比例。
例如对于一个剪切变换A=[■(1&1@0&1)]，单位正方形变为一个平行四边形，但面积还是1（上三角行列式|A|=1）。
对于一个特殊情况情况行列式为0，|■(4&2@2&1)|=0，含义为[■(4&2@2&1)]变换将平面平面压缩到一条线上，即检验一个行列式是否为0就可以知道矩阵代表的变换是否压缩了空间。
三维空间中也是类似的，|A_(3×3) |=0表明矩阵A代表的变换将空间压缩为一个平面，或是一条线甚至是一个点，即矩阵的列线性相关
行列式为负，则是定向问题。
对于行列式的计算，以二维变换为例，对角阵[■(a&0@0&d)]最容易理解，正方形变换为矩形的面积，三角阵[■(a&b@0&d)]则变换为平行四边形，虽然做了剪切但是面积不变。最一般的情况[■(a&b@c&d)]，粗略的讲bc项代表了平行四边形拉伸的多少。
 
最后对于|AB|=|A||B|的理解，，符合变换后面积变化倍数=B变换倍数*A变换倍数。

## 逆矩阵、列空间、秩、零空间

矩阵的有用之处：描述对空间的操纵、计算图形学和机器人学中有应用，此外矩阵的一大用途是求解线性方程组。
例如方程组：
{█(2x+5y+3z=-3@4x+0y+8z=0@1x+3y+0z=2)┤⟺[■(2&5&3@4&0&8@1&3&0)][■(x@y@z)]=[■(-3@0@2)]
让A=[■(2&5&3@4&0&8@1&3&0)]，x=[■(x@y@z)]，b=[■(-3@0@2)]，这样线性方程组可以写成Ax=b，这种写法并非简化的书写技巧，而是阐明了几何直观部分：A为一个线性变换，求解Ax=b意味着要寻找一个向量x使得在A变换下为b。
先考虑一个简单的例子：
[■(2&2@1&3)][■(x@y)]=[■(-4@-1)]
这个方程的解依赖于A变换，考虑两个情况：|A|=0和|A|≠0。
当|A|≠0时，A变换没有把空间挤压到更低维度，这样有且仅有一个向量与b重合，可以通过A的逆向变换去找x，这个逆向变换写作A^(-1)。比如A^(-1) Ax=x，几何解释为x经过A变换和A^(-1)变换后仍然为x，A^(-1) A=E即为什么都不做的一个矩阵。因此向量方程的解为A^(-1) Ax=A^(-1) b，即x=A^(-1) b，几何上为给b做一个反向变换。
当|A|=0时，A变换把空间挤压到更低维度，当解存在（b恰好在在A变换后的空间内），当一个变换结果为直线也称秩为1，即秩为变换后空间的维数。A的列向量为变换后的基向量，列向量张成的空间（列空间）就是所有可能的变换结果。零向量[0,0]^T（原点）一定会被包含在列空间里，满秩变换能落在原点的只有自身，对于不满秩的情况，会有一系列向量变为0向量，变换后落在原点的向量集合被称为矩阵的“零空间”或“核”，对于线性方程组来说b=0时，解即为零空间，也叫齐次方程组额额基础解系。

非方阵

讨论一个不同维度之间的变换
[■(2@7)]→L(x)→[■(1@8@2)]
平面映射到了三维空间
[■(3&1@4&1@5&9)][■(x@y)]=xi ̂+yj ̂
三维映射二维
[■(3&1&4@1&5&9)][■(x@y@z)]=xi ̂+yj ̂+zk ̂
二维映射一维
[■(1&2)][■(x@y)]

## 基变换

一个向量在空间中，我们可以用坐标表示比如a=[3,2]^T，在描述这个向量的坐标时，用了一个隐含假设a=[i,j] [3,2]^T=3i+2j。即我们选用了一组基，现在我们选用另一组向量来描述同一个向量。
ij为标准坐标系E=[i,j]，i ̂j ̂为新坐标系，P=[i ̂,j ̂]。
i ̂在E中为[■(2@1)]，j ̂在E中为[■(-1@1)]；i ̂在P中为[■(1@0)]，j ̂在P中为[■(0@1)]。
在P中描述的a为a=[i ̂,j ̂ ] [3,2]^T=3i ̂+2j ̂，此时的[■(3@2)]为P坐标系的坐标，为了得到在E坐标系中的坐标，计算出结果即可a=[i ̂,j ̂ ] [3,2]^T=[■(2&-1@1&1)][■(3@2)]=[■(4@5)]，或者理解为在坐标系P描述的a在E坐标系中的坐标值。即Pa为E坐标系的中a的坐标。
接下来考虑一个变换A=[■(0&-1@1&1)]，对E坐标系中的向量进行变换，这个变换如何在P坐标系中对a进行？
P^(-1) APa
上述变换描述了E坐标系中A变换对P坐标系中向量进行。P^(-1) AP暗示着数学上的转移作用，描述了同一个变换再不同视角下进行的。


## 变换的不变量：特征值与特征向量

向量在矩阵变换的作用下，有一些特殊的向量不离开其张成的空间，仅仅被拉伸或压缩。即矩阵的作用相当于一个标量。比如矩阵A=[■(3&0@0&2)]代表的变换，i ̂,j ̂方向的向量没有离开其所在直线（张成的空间），可以猜出，i ̂,j ̂为变换P的特征向量，3和为对应的特征值。
特征值和特征向量为什么有用？考虑一个在三维空间中的旋转变换，找到特征向量就找到了旋转轴，这种情况下特征值通常为1，这在机器人运动学中有应用。
对于任一矩阵描述的线性变换，可以将列看作变换后的基向量，但理解线性变换作用的关键往往较少依赖于特定坐标系，更好的方法是求出特征向量和特征值。
用数学语言描述“向量在矩阵变换的作用下，有不离开其张成的空间”为：Aξ=λξ，因此找特征向量和特征值就是找使得等式成立的λ和ξ，即(λE-A)ξ=0，当|λE-A|=0时，会有有意义的ξ（非0，即非原点）找出被压缩的空间就是特征空间。
考虑一个基向量刚好是特征向量的矩阵A=[■(3&0@0&2)]，这个矩阵的优秀性质是是计算n次幂更方便，不太容易去找一个基向量恰好是特征向量的矩阵，但是如果一个矩阵的特征向量可以张成全空间，由前面的基变换，用特征向量当做基。对一个普通变换矩阵 A=[■(a&b@c&d)]，其特征向量为ξ_1和ξ_2，P=[■(ξ_1&ξ_2 )]。A变换在特征基中的描述方式则为（x为P中的坐标）：
P^(-1) APx=Λx
Λ是对角阵的原因：A变换仅拉伸特征向量，x以特征向量为基向量。类比二维空间矩形面积，高维空间的高维立方体体积也为棱长（边长）的乘积，即为特征值的乘积，又因为A和Λ是同一个变换再不同坐标系下的描述，去掉坐标系从空间中看没啥区别，因此有
|A|=∏_1^n▒λ_i 
同样根据相似矩阵也是在不同坐标系描述同一个变换，因此其缩放系数相同，特征向量也相同。

## 实对称矩阵的对角化

以一个实对称的二阶变换矩阵A=[■(2&1@1&2)]为例，显然列向量关于直线y=x对称，也不难看出其代表的变换不会改变

## 二次型

二次型即二次函数（二次方程），起源于几何学中的圆锥曲线方程（抛物线，双曲线，椭圆和圆）。
二次型可以表示为一个矩阵表达式f(x)=x^T Ax，其中A为实对称矩阵，因此可以使用矩阵理论来研究一个二次曲线，应用基变换、线性映射的手段来求一些二次曲线的极值。
A表示了系数，x为一个坐标。实对称矩阵A可以使用正交矩阵Q相似对角化，A为一个变换，这个变换在特征基的视角下看看为，